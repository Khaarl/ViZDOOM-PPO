{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1ut4skXBOXQJo_bjT_9PqUpOtZSuvRRdL",
      "authorship_tag": "ABX9TyPx89lkBVaPpFzpLon7yuXR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Khaarl/ViZDOOM-PPO/blob/STAGING/ViZDOOM_PPO2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Dependencies\n",
        "\n",
        "!apt-get update\n",
        "!apt-get install -y build-essential zlib1g-dev libsdl2-dev libjpeg-dev \\\n",
        "    nasm tar libbz2-dev libgtk2.0-dev cmake git libfluidsynth-dev libgme-dev \\\n",
        "    libopenal-dev timidity libwildmidi-dev unzip ffmpeg\n",
        "\n",
        "!pip install vizdoom\n",
        "!pip install stable-baselines3[extra]\n",
        "\n",
        "# Set up logging and directory structure\n",
        "\n",
        "import os\n",
        "import logging\n",
        "\n",
        "# Define local paths for scenario and storage\n",
        "LOCAL_SCENARIO_PATH = \"/content/scenarios/deathmatch.cfg\"\n",
        "LOCAL_STORAGE_PATH = \"/content/scenarios/training_data\"\n",
        "LOCAL_MODEL_PATH = \"/content/scenarios/training_data/models\"\n",
        "LOCAL_LOG_PATH = \"/content/scenarios/training_data/logs\"\n",
        "LOCAL_TENSORBOARD_PATH = \"/content/scenarios/training_data/tensorboard\"\n",
        "LOCAL_WAD_PATH = \"/content/scenarios/freedoom2.wad\"\n",
        "\n",
        "# Create local directories\n",
        "os.makedirs(LOCAL_STORAGE_PATH, exist_ok=True)\n",
        "os.makedirs(LOCAL_MODEL_PATH, exist_ok=True)\n",
        "os.makedirs(LOCAL_LOG_PATH, exist_ok=True)\n",
        "os.makedirs(LOCAL_TENSORBOARD_PATH, exist_ok=True)\n",
        "print(\"Created local directories.\")\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(filename=os.path.join(LOCAL_LOG_PATH, 'setup.log'), level=logging.INFO,\n",
        "                    format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logging.info(\"Directories created and logging configured.\")\n",
        "\n",
        "# Download freedoom2.wad if it doesn't exist\n",
        "if not os.path.exists(LOCAL_WAD_PATH):\n",
        "    !wget https://github.com/freedoom/freedoom/releases/download/v0.13.0/freedoom2.wad -O $LOCAL_WAD_PATH\n",
        "    logging.info(f\"Downloaded freedoom2.wad to {LOCAL_WAD_PATH}\")\n",
        "else:\n",
        "    logging.info(f\"Using existing freedoom2.wad at {LOCAL_WAD_PATH}\")\n",
        "\n",
        "# Download deathmatch.cfg if it doesn't exist\n",
        "if not os.path.exists(LOCAL_SCENARIO_PATH):\n",
        "    !wget https://raw.githubusercontent.com/mwydmuch/ViZDoom/master/scenarios/deathmatch.cfg -P /content/scenarios/\n",
        "    logging.info(f\"Downloaded deathmatch.cfg to {LOCAL_SCENARIO_PATH}\")\n",
        "else:\n",
        "    logging.info(f\"Using existing deathmatch.cfg at {LOCAL_SCENARIO_PATH}\")\n",
        "\n",
        "# Define configuration constants and helper functions\n",
        "\n",
        "def get_user_input(prompt, type_=None, min_=None, max_=None, range_=None):\n",
        "    if min_ is not None and max_ is not None and max_ < min_:\n",
        "        raise ValueError(\"min_ must be less than or equal to max_.\")\n",
        "    while True:\n",
        "        val = input(prompt)\n",
        "        if type_ is not None:\n",
        "            try:\n",
        "                val = type_(val)\n",
        "            except ValueError:\n",
        "                print(f\"Input must be of type {type_.__name__}.\")\n",
        "                continue\n",
        "        if min_ is not None and val < min_:\n",
        "            print(f\"Input must be greater than or equal to {min_}.\")\n",
        "        elif max_ is not None and val > max_:\n",
        "            print(f\"Input must be less than or equal to {max_}.\")\n",
        "        elif range_ is not None and val not in range_:\n",
        "            if isinstance(range_, range):\n",
        "                template = f\"Input must be between {range_.start} and {range_.stop-1}.\"\n",
        "            else:\n",
        "                template = f\"Input must be {', '.join(map(str, range_))}.\"\n",
        "            print(template)\n",
        "        else:\n",
        "            return val\n",
        "\n",
        "logging.info(\"Helper functions defined.\")"
      ],
      "metadata": {
        "id": "RlkMjUx5_bY4",
        "outputId": "857b9d72-705a-4643-e715-fe86ba1bde6a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "\r0% [Connecting to archive.ubuntu.com] [1 InRelease 14.2 kB/129 kB 11%] [Connected to cloud.r-project\r                                                                                                    \rHit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:4 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:9 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,227 kB]\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Fetched 1,356 kB in 2s (862 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "build-essential is already the newest version (12.9ubuntu3).\n",
            "libbz2-dev is already the newest version (1.0.8-5build1).\n",
            "libjpeg-dev is already the newest version (8c-2ubuntu10).\n",
            "libfluidsynth-dev is already the newest version (2.2.5-1).\n",
            "libgme-dev is already the newest version (0.6.3-2).\n",
            "libopenal-dev is already the newest version (1:1.19.1-2build3).\n",
            "libwildmidi-dev is already the newest version (0.4.3-1).\n",
            "nasm is already the newest version (2.15.05-1).\n",
            "cmake is already the newest version (3.22.1-1ubuntu1.22.04.2).\n",
            "git is already the newest version (1:2.34.1-1ubuntu1.11).\n",
            "tar is already the newest version (1.34+dfsg-1ubuntu0.1.22.04.2).\n",
            "unzip is already the newest version (6.0-26ubuntu3.2).\n",
            "zlib1g-dev is already the newest version (1:1.2.11.dfsg-2ubuntu9.2).\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "libgtk2.0-dev is already the newest version (2.24.33-2ubuntu2.1).\n",
            "libsdl2-dev is already the newest version (2.0.20+dfsg-2ubuntu1.22.04.1).\n",
            "timidity is already the newest version (2.14.0-8ubuntu1.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 50 not upgraded.\n",
            "Requirement already satisfied: vizdoom in /usr/local/lib/python3.10/dist-packages (1.2.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from vizdoom) (1.26.4)\n",
            "Requirement already satisfied: gymnasium>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from vizdoom) (1.0.0)\n",
            "Requirement already satisfied: pygame>=2.1.3 in /usr/local/lib/python3.10/dist-packages (from vizdoom) (2.6.1)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=0.28.0->vizdoom) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=0.28.0->vizdoom) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=0.28.0->vizdoom) (0.0.4)\n",
            "Requirement already satisfied: stable-baselines3[extra] in /usr/local/lib/python3.10/dist-packages (2.4.1)\n",
            "Requirement already satisfied: gymnasium<1.1.0,>=0.29.1 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (1.0.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.20 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (1.26.4)\n",
            "Requirement already satisfied: torch>=1.13 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (2.5.1+cu121)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (3.1.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (3.10.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (4.10.0.84)\n",
            "Requirement already satisfied: pygame in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (2.6.1)\n",
            "Requirement already satisfied: tensorboard>=2.9.1 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (2.17.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (5.9.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (4.67.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (13.9.4)\n",
            "Requirement already satisfied: ale-py>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (0.10.1)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[extra]) (11.1.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from ale-py>=0.9.0->stable-baselines3[extra]) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium<1.1.0,>=0.29.1->stable-baselines3[extra]) (0.0.4)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.69.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (4.25.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (75.1.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.1.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (3.16.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[extra]) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.13->stable-baselines3[extra]) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[extra]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->stable-baselines3[extra]) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->stable-baselines3[extra]) (2024.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->stable-baselines3[extra]) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->stable-baselines3[extra]) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->stable-baselines3[extra]) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->stable-baselines3[extra]) (3.0.2)\n",
            "Created local directories.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom ViZDoom Environment Class\n",
        "\n",
        "from vizdoom import *\n",
        "import numpy as np\n",
        "import gymnasium as gym\n",
        "from gymnasium import spaces\n",
        "\n",
        "class VizdoomEnv(gym.Env):\n",
        "    def __init__(self, scenario_path, frame_skip=4):\n",
        "        super(VizdoomEnv, self).__init__()\n",
        "        self.game = DoomGame()\n",
        "        self.game.load_config(scenario_path)\n",
        "        self.game.set_doom_game_path(LOCAL_WAD_PATH)\n",
        "        self.game.set_window_visible(False)\n",
        "        self.game.set_mode(Mode.PLAYER)\n",
        "        self.game.set_screen_format(ScreenFormat.GRAY8)\n",
        "        self.game.set_screen_resolution(ScreenResolution.RES_640X480)\n",
        "        self.game.init()\n",
        "\n",
        "        self.frame_skip = frame_skip\n",
        "        self.action_space = spaces.Discrete(self.game.get_available_buttons_size())\n",
        "        self.observation_space = spaces.Box(low=0, high=255, shape=(self.game.get_screen_height(), self.game.get_screen_width(), 1), dtype=np.uint8)\n",
        "\n",
        "        self.previous_game_variables = None\n",
        "\n",
        "    def step(self, action):\n",
        "        buttons = np.zeros(self.game.get_available_buttons_size())\n",
        "        buttons[action] = 1\n",
        "\n",
        "        reward = self.game.make_action(buttons.tolist(), self.frame_skip)\n",
        "        done = self.game.is_episode_finished()\n",
        "\n",
        "        state = self.game.get_state().screen_buffer if not done else np.zeros(self.observation_space.shape, dtype=np.uint8)\n",
        "        state = np.expand_dims(state, axis=-1)\n",
        "\n",
        "        shaped_reward = reward + self._shape_reward()\n",
        "\n",
        "        return state, shaped_reward, done, False, {}\n",
        "\n",
        "    def _shape_reward(self):\n",
        "        current_game_vars = self.game.get_state().game_variables if self.game.get_state() else None\n",
        "        reward = 0\n",
        "\n",
        "        if current_game_vars is None or self.previous_game_variables is None:\n",
        "            self.previous_game_variables = current_game_vars\n",
        "            return reward\n",
        "\n",
        "        reward += (current_game_vars[0] - self.previous_game_variables[0]) * 100.0\n",
        "        reward -= (self.previous_game_variables[2] - current_game_vars[2]) * 0.1\n",
        "        reward -= (self.previous_game_variables[1] - current_game_vars[1])\n",
        "        reward += 0.1\n",
        "\n",
        "        min_dist_now = self._get_closest_enemy_distance()\n",
        "        if hasattr(self, 'min_dist_prev'):\n",
        "            if min_dist_now < self.min_dist_prev and min_dist_now < 500:\n",
        "                reward += 0.05\n",
        "            elif min_dist_now > self.min_dist_prev and self.min_dist_prev < 500:\n",
        "                reward -= 0.05\n",
        "        self.min_dist_prev = min_dist_now\n",
        "\n",
        "        self.previous_game_variables = current_game_vars\n",
        "\n",
        "        return reward\n",
        "\n",
        "    def _get_closest_enemy_distance(self):\n",
        "        min_dist = float('inf')\n",
        "        current_game_vars = self.game.get_state().game_variables if self.game.get_state() else None\n",
        "\n",
        "        if current_game_vars is None:\n",
        "            return min_dist\n",
        "\n",
        "        px, py = current_game_vars[3], current_game_vars[4]\n",
        "\n",
        "        for obj in self.game.get_state().objects:\n",
        "            if obj.is_enemy():\n",
        "                dist = ((px - obj.position_x)**2 + (py - obj.position_y)**2)**0.5\n",
        "                min_dist = min(min_dist, dist)\n",
        "\n",
        "        return min_dist\n",
        "\n",
        "    def reset(self, seed=None, options=None):\n",
        "        super().reset(seed=seed)\n",
        "        self.game.new_episode()\n",
        "        state = self.game.get_state().screen_buffer\n",
        "        state = np.expand_dims(state, axis=-1)\n",
        "        self.previous_game_variables = None\n",
        "        self.min_dist_prev = float('inf')\n",
        "        return state, {}\n",
        "\n",
        "    def close(self):\n",
        "        self.game.close()\n",
        "\n",
        "# Unit tests for VizdoomEnv\n",
        "\n",
        "import unittest\n",
        "\n",
        "class TestVizdoomEnv(unittest.TestCase):\n",
        "    def setUp(self):\n",
        "        self.env = VizdoomEnv(LOCAL_SCENARIO_PATH)\n",
        "\n",
        "    def test_initialization(self):\n",
        "        self.assertIsInstance(self.env, gym.Env)\n",
        "        self.assertIsNotNone(self.env.game)\n",
        "        self.assertEqual(self.env.frame_skip, 4)\n",
        "\n",
        "    def test_step(self):\n",
        "        state, reward, done, _, _ = self.env.step(0)\n",
        "        self.assertEqual(state.shape, self.env.observation_space.shape)\n",
        "        self.assertIsInstance(reward, float)\n",
        "        self.assertIsInstance(done, bool)\n",
        "\n",
        "    def test_reset(self):\n",
        "        state, _ = self.env.reset()\n",
        "        self.assertEqual(state.shape, self.env.observation_space.shape)\n",
        "\n",
        "    def test_close(self):\n",
        "        self.env.close()\n",
        "        self.assertFalse(self.env.game.is_running())\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    unittest.main(argv=[''], exit=False)"
      ],
      "metadata": {
        "id": "iAJg8gZ8_kZg",
        "outputId": "45e392d9-6305-4722-bd1c-4f7b298ff67a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "EEEE\n",
            "======================================================================\n",
            "ERROR: test_close (__main__.TestVizdoomEnv)\n",
            "----------------------------------------------------------------------\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-3-c495c9751958>\", line 99, in setUp\n",
            "    self.env = VizdoomEnv(LOCAL_SCENARIO_PATH)\n",
            "  File \"<ipython-input-3-c495c9751958>\", line 18, in __init__\n",
            "    self.game.init()\n",
            "vizdoom.vizdoom.FileDoesNotExistException: File \"/content/scenarios/deathmatch.wad\" does not exist.\n",
            "\n",
            "======================================================================\n",
            "ERROR: test_initialization (__main__.TestVizdoomEnv)\n",
            "----------------------------------------------------------------------\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-3-c495c9751958>\", line 99, in setUp\n",
            "    self.env = VizdoomEnv(LOCAL_SCENARIO_PATH)\n",
            "  File \"<ipython-input-3-c495c9751958>\", line 18, in __init__\n",
            "    self.game.init()\n",
            "vizdoom.vizdoom.FileDoesNotExistException: File \"/content/scenarios/deathmatch.wad\" does not exist.\n",
            "\n",
            "======================================================================\n",
            "ERROR: test_reset (__main__.TestVizdoomEnv)\n",
            "----------------------------------------------------------------------\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-3-c495c9751958>\", line 99, in setUp\n",
            "    self.env = VizdoomEnv(LOCAL_SCENARIO_PATH)\n",
            "  File \"<ipython-input-3-c495c9751958>\", line 18, in __init__\n",
            "    self.game.init()\n",
            "vizdoom.vizdoom.FileDoesNotExistException: File \"/content/scenarios/deathmatch.wad\" does not exist.\n",
            "\n",
            "======================================================================\n",
            "ERROR: test_step (__main__.TestVizdoomEnv)\n",
            "----------------------------------------------------------------------\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-3-c495c9751958>\", line 99, in setUp\n",
            "    self.env = VizdoomEnv(LOCAL_SCENARIO_PATH)\n",
            "  File \"<ipython-input-3-c495c9751958>\", line 18, in __init__\n",
            "    self.game.init()\n",
            "vizdoom.vizdoom.FileDoesNotExistException: File \"/content/scenarios/deathmatch.wad\" does not exist.\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Ran 4 tests in 0.018s\n",
            "\n",
            "FAILED (errors=4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PPO Agent Configuration\n",
        "\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.callbacks import CheckpointCallback\n",
        "from stable_baselines3.common.monitor import Monitor\n",
        "import torch as th\n",
        "\n",
        "# Define PPO hyperparameters with input validation\n",
        "def get_ppo_hyperparameters():\n",
        "    learning_rate = get_user_input(\"Enter the learning rate (e.g., 0.0003): \", type_=float, min_=1e-6, max_=1e-1)\n",
        "    n_steps = get_user_input(\"Enter the number of steps to run for each environment per update (e.g., 2048): \", type_=int, min_=1)\n",
        "    batch_size = get_user_input(\"Enter the batch size (e.g., 64): \", type_=int, min_=1)\n",
        "    n_epochs = get_user_input(\"Enter the number of epochs (e.g., 10): \", type_=int, min_=1)\n",
        "    gamma = get_user_input(\"Enter the discount factor (e.g., 0.99): \", type_=float, min_=0.0, max_=1.0)\n",
        "    gae_lambda = get_user_input(\"Enter the GAE lambda (e.g., 0.95): \", type_=float, min_=0.0, max_=1.0)\n",
        "    clip_range = get_user_input(\"Enter the clip range (e.g., 0.2): \", type_=float, min_=0.0, max_=1.0)\n",
        "    ent_coef = get_user_input(\"Enter the entropy coefficient (e.g., 0.01): \", type_=float, min_=0.0, max_=1.0)\n",
        "    vf_coef = get_user_input(\"Enter the value function coefficient (e.g., 0.5): \", type_=float, min_=0.0, max_=1.0)\n",
        "    max_grad_norm = get_user_input(\"Enter the maximum gradient norm (e.g., 0.5): \", type_=float, min_=0.0, max_=10.0)\n",
        "    return {\n",
        "        \"learning_rate\": learning_rate,\n",
        "        \"n_steps\": n_steps,\n",
        "        \"batch_size\": batch_size,\n",
        "        \"n_epochs\": n_epochs,\n",
        "        \"gamma\": gamma,\n",
        "        \"gae_lambda\": gae_lambda,\n",
        "        \"clip_range\": clip_range,\n",
        "        \"ent_coef\": ent_coef,\n",
        "        \"vf_coef\": vf_coef,\n",
        "        \"max_grad_norm\": max_grad_norm\n",
        "    }\n",
        "\n",
        "# Get PPO hyperparameters from user\n",
        "ppo_hyperparameters = get_ppo_hyperparameters()\n",
        "logging.info(f\"PPO hyperparameters: {ppo_hyperparameters}\")\n",
        "\n",
        "# Define neural network architecture\n",
        "policy_kwargs = dict(\n",
        "    activation_fn=th.nn.ReLU,\n",
        "    net_arch=[dict(pi=[64, 64], vf=[64, 64])]\n",
        ")\n",
        "\n",
        "# Create and configure PPO agent\n",
        "try:\n",
        "    env = VizdoomEnv(LOCAL_SCENARIO_PATH)\n",
        "    env = Monitor(env, LOCAL_LOG_PATH)\n",
        "    model = PPO(\n",
        "        \"CnnPolicy\",\n",
        "        env,\n",
        "        verbose=1,\n",
        "        tensorboard_log=LOCAL_TENSORBOARD_PATH,\n",
        "        policy_kwargs=policy_kwargs,\n",
        "        **ppo_hyperparameters\n",
        "    )\n",
        "    logging.info(\"PPO agent created successfully.\")\n",
        "except Exception as e:\n",
        "    logging.error(f\"Error creating PPO agent: {e}\")\n",
        "    print(f\"Error creating PPO agent: {e}\")\n",
        "    exit()\n",
        "\n",
        "# Define checkpoint callback\n",
        "checkpoint_callback = CheckpointCallback(\n",
        "    save_freq=max(10000, ppo_hyperparameters[\"n_steps\"] // 10),\n",
        "    save_path=LOCAL_MODEL_PATH,\n",
        "    name_prefix=\"ppo_vizdoom\"\n",
        ")\n",
        "\n",
        "# Train the PPO agent\n",
        "try:\n",
        "    model.learn(total_timesteps=ppo_hyperparameters[\"n_steps\"], callback=checkpoint_callback)\n",
        "    logging.info(\"PPO agent training completed.\")\n",
        "except Exception as e:\n",
        "    logging.error(f\"Error during PPO agent training: {e}\")\n",
        "    print(f\"Error during PPO agent training: {e}\")\n",
        "    if env:\n",
        "        env.close()\n",
        "    exit()\n",
        "\n",
        "# Save the final model\n",
        "final_model_path = os.path.join(LOCAL_MODEL_PATH, \"ppo_vizdoom_final\")\n",
        "try:\n",
        "    model.save(final_model_path)\n",
        "    logging.info(f\"Final PPO model saved to: {final_model_path}\")\n",
        "except Exception as e:\n",
        "    logging.error(f\"Error saving final PPO model: {e}\")\n",
        "    print(f\"Error saving final PPO model: {e}\")\n",
        "\n",
        "# Close the environment\n",
        "if env:\n",
        "    env.close()\n",
        "logging.info(\"Environment closed.\")"
      ],
      "metadata": {
        "id": "hzTtnEYs_sHY",
        "outputId": "50eb8ad2-b110-4a7a-81d0-e80fc9016b65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 766
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter the learning rate (e.g., 0.0003): \n",
            "Input must be of type float.\n",
            "Enter the learning rate (e.g., 0.0003): \n",
            "Input must be of type float.\n",
            "Enter the learning rate (e.g., 0.0003): \n",
            "Input must be of type float.\n",
            "Enter the learning rate (e.g., 0.0003): 0.03\n",
            "Enter the number of steps to run for each environment per update (e.g., 2048): 2048\n",
            "Enter the batch size (e.g., 64): 64\n",
            "Enter the number of epochs (e.g., 10): 10\n",
            "Enter the discount factor (e.g., 0.99): 0.99\n",
            "Enter the GAE lambda (e.g., 0.95): \n",
            "Input must be of type float.\n",
            "Enter the GAE lambda (e.g., 0.95): 0.95\n",
            "Enter the clip range (e.g., 0.2): 0.2\n",
            "Enter the entropy coefficient (e.g., 0.01): 0.01\n",
            "Enter the value function coefficient (e.g., 0.5): 0.5\n",
            "Enter the maximum gradient norm (e.g., 0.5): 0.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:Error creating PPO agent: File \"/content/scenarios/deathmatch.wad\" does not exist.\n",
            "ERROR:root:Error during PPO agent training: name 'model' is not defined\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error creating PPO agent: File \"/content/scenarios/deathmatch.wad\" does not exist.\n",
            "Error during PPO agent training: name 'model' is not defined\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'env' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-8da7184d9f2d>\u001b[0m in \u001b[0;36m<cell line: 69>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mppo_hyperparameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"n_steps\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheckpoint_callback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"PPO agent training completed.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-8da7184d9f2d>\u001b[0m in \u001b[0;36m<cell line: 69>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Error during PPO agent training: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Error during PPO agent training: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'env' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Pipeline\n",
        "\n",
        "import os\n",
        "import logging\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.callbacks import CheckpointCallback, EvalCallback\n",
        "from stable_baselines3.common.monitor import Monitor\n",
        "import torch as th\n",
        "\n",
        "# Define PPO hyperparameters with input validation\n",
        "def get_ppo_hyperparameters():\n",
        "    learning_rate = get_user_input(\"Enter the learning rate (e.g., 0.0003): \", type_=float, min_=1e-6, max_=1e-1)\n",
        "    n_steps = get_user_input(\"Enter the number of steps to run for each environment per update (e.g., 2048): \", type_=int, min_=1)\n",
        "    batch_size = get_user_input(\"Enter the batch size (e.g., 64): \", type_=int, min_=1)\n",
        "    n_epochs = get_user_input(\"Enter the number of epochs (e.g., 10): \", type_=int, min_=1)\n",
        "    gamma = get_user_input(\"Enter the discount factor (e.g., 0.99): \", type_=float, min_=0.0, max_=1.0)\n",
        "    gae_lambda = get_user_input(\"Enter the GAE lambda (e.g., 0.95): \", type_=float, min_=0.0, max_=1.0)\n",
        "    clip_range = get_user_input(\"Enter the clip range (e.g., 0.2): \", type_=float, min_=0.0, max_=1.0)\n",
        "    ent_coef = get_user_input(\"Enter the entropy coefficient (e.g., 0.01): \", type_=float, min_=0.0, max_=1.0)\n",
        "    vf_coef = get_user_input(\"Enter the value function coefficient (e.g., 0.5): \", type_=float, min_=0.0, max_=1.0)\n",
        "    max_grad_norm = get_user_input(\"Enter the maximum gradient norm (e.g., 0.5): \", type_=float, min_=0.0, max_=10.0)\n",
        "    return {\n",
        "        \"learning_rate\": learning_rate,\n",
        "        \"n_steps\": n_steps,\n",
        "        \"batch_size\": batch_size,\n",
        "        \"n_epochs\": n_epochs,\n",
        "        \"gamma\": gamma,\n",
        "        \"gae_lambda\": gae_lambda,\n",
        "        \"clip_range\": clip_range,\n",
        "        \"ent_coef\": ent_coef,\n",
        "        \"vf_coef\": vf_coef,\n",
        "        \"max_grad_norm\": max_grad_norm\n",
        "    }\n",
        "\n",
        "# Get PPO hyperparameters from user\n",
        "ppo_hyperparameters = get_ppo_hyperparameters()\n",
        "logging.info(f\"PPO hyperparameters: {ppo_hyperparameters}\")\n",
        "\n",
        "# Define neural network architecture\n",
        "policy_kwargs = dict(\n",
        "    activation_fn=th.nn.ReLU,\n",
        "    net_arch=[dict(pi=[64, 64], vf=[64, 64])]\n",
        ")\n",
        "\n",
        "# Create and configure PPO agent\n",
        "try:\n",
        "    env = VizdoomEnv(LOCAL_SCENARIO_PATH)\n",
        "    env = Monitor(env, LOCAL_LOG_PATH)\n",
        "    model = PPO(\n",
        "        \"CnnPolicy\",\n",
        "        env,\n",
        "        verbose=1,\n",
        "        tensorboard_log=LOCAL_TENSORBOARD_PATH,\n",
        "        policy_kwargs=policy_kwargs,\n",
        "        **ppo_hyperparameters\n",
        "    )\n",
        "    logging.info(\"PPO agent created successfully.\")\n",
        "except Exception as e:\n",
        "    logging.error(f\"Error creating PPO agent: {e}\")\n",
        "    print(f\"Error creating PPO agent: {e}\")\n",
        "    exit()\n",
        "\n",
        "# Define checkpoint callback\n",
        "checkpoint_callback = CheckpointCallback(\n",
        "    save_freq=max(10000, ppo_hyperparameters[\"n_steps\"] // 10),\n",
        "    save_path=LOCAL_MODEL_PATH,\n",
        "    name_prefix=\"ppo_vizdoom\"\n",
        ")\n",
        "\n",
        "# Define evaluation callback for early stopping\n",
        "eval_callback = EvalCallback(\n",
        "    env,\n",
        "    best_model_save_path=LOCAL_MODEL_PATH,\n",
        "    log_path=LOCAL_LOG_PATH,\n",
        "    eval_freq=max(10000, ppo_hyperparameters[\"n_steps\"] // 10),\n",
        "    deterministic=True,\n",
        "    render=False\n",
        ")\n",
        "\n",
        "# Train the PPO agent\n",
        "try:\n",
        "    model.learn(total_timesteps=ppo_hyperparameters[\"n_steps\"], callback=[checkpoint_callback, eval_callback])\n",
        "    logging.info(\"PPO agent training completed.\")\n",
        "except Exception as e:\n",
        "    logging.error(f\"Error during PPO agent training: {e}\")\n",
        "    print(f\"Error during PPO agent training: {e}\")\n",
        "    if env:\n",
        "        env.close()\n",
        "    exit()\n",
        "\n",
        "# Save the final model\n",
        "final_model_path = os.path.join(LOCAL_MODEL_PATH, \"ppo_vizdoom_final\")\n",
        "try:\n",
        "    model.save(final_model_path)\n",
        "    logging.info(f\"Final PPO model saved to: {final_model_path}\")\n",
        "except Exception as e:\n",
        "    logging.error(f\"Error saving final PPO model: {e}\")\n",
        "    print(f\"Error saving final PPO model: {e}\")\n",
        "\n",
        "# Close the environment\n",
        "if env:\n",
        "    env.close()\n",
        "logging.info(\"Environment closed.\")"
      ],
      "metadata": {
        "id": "fwD0D7jV_zsz",
        "outputId": "3c8371fe-ebf2-4f13-cc57-130586f2898d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'get_user_input' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-9523c6538b2e>\u001b[0m in \u001b[0;36m<cell line: 36>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;31m# Get PPO hyperparameters from user\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m \u001b[0mppo_hyperparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_ppo_hyperparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"PPO hyperparameters: {ppo_hyperparameters}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-9523c6538b2e>\u001b[0m in \u001b[0;36mget_ppo_hyperparameters\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Define PPO hyperparameters with input validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_ppo_hyperparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_user_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Enter the learning rate (e.g., 0.0003): \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mn_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_user_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Enter the number of steps to run for each environment per update (e.g., 2048): \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_user_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Enter the batch size (e.g., 64): \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'get_user_input' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Management\n",
        "\n",
        "import os\n",
        "import logging\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.callbacks import CheckpointCallback, EvalCallback\n",
        "from stable_baselines3.common.monitor import Monitor\n",
        "import torch as th\n",
        "\n",
        "# Function to save the model with version control\n",
        "def save_model_with_version(model, save_path, version):\n",
        "    versioned_path = f\"{save_path}_v{version}\"\n",
        "    try:\n",
        "        model.save(versioned_path)\n",
        "        logging.info(f\"Model saved to: {versioned_path}\")\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Error saving model to {versioned_path}: {e}\")\n",
        "        print(f\"Error saving model to {versioned_path}: {e}\")\n",
        "\n",
        "# Function to load the model with security validation\n",
        "def load_model_with_validation(model_path):\n",
        "    if os.path.exists(model_path):\n",
        "        try:\n",
        "            model = PPO.load(model_path)\n",
        "            logging.info(f\"Model loaded from: {model_path}\")\n",
        "            return model\n",
        "        except Exception as e:\n",
        "            logging.error(f\"Error loading model from {model_path}: {e}\")\n",
        "            print(f\"Error loading model from {model_path}: {e}\")\n",
        "            return None\n",
        "    else:\n",
        "        logging.error(f\"Model path does not exist: {model_path}\")\n",
        "        print(f\"Model path does not exist: {model_path}\")\n",
        "        return None\n",
        "\n",
        "# Function to evaluate the model\n",
        "def evaluate_model(model, env, num_episodes=10):\n",
        "    episode_rewards = []\n",
        "    for _ in range(num_episodes):\n",
        "        obs = env.reset()\n",
        "        done = False\n",
        "        total_reward = 0\n",
        "        while not done:\n",
        "            action, _states = model.predict(obs, deterministic=True)\n",
        "            obs, reward, done, _, _ = env.step(action)\n",
        "            total_reward += reward\n",
        "        episode_rewards.append(total_reward)\n",
        "    avg_reward = sum(episode_rewards) / num_episodes\n",
        "    logging.info(f\"Average reward over {num_episodes} episodes: {avg_reward}\")\n",
        "    return avg_reward\n",
        "\n",
        "# Function to visualize evaluation metrics\n",
        "def visualize_evaluation_metrics(rewards):\n",
        "    import matplotlib.pyplot as plt\n",
        "    plt.plot(rewards)\n",
        "    plt.xlabel('Episode')\n",
        "    plt.ylabel('Reward')\n",
        "    plt.title('Model Evaluation Metrics')\n",
        "    plt.show()\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Define paths and version\n",
        "    model_save_path = os.path.join(LOCAL_MODEL_PATH, \"ppo_vizdoom\")\n",
        "    model_version = 1\n",
        "\n",
        "    # Save the model with version control\n",
        "    save_model_with_version(model, model_save_path, model_version)\n",
        "\n",
        "    # Load the model with validation\n",
        "    loaded_model = load_model_with_validation(f\"{model_save_path}_v{model_version}\")\n",
        "\n",
        "    # Evaluate the model\n",
        "    if loaded_model:\n",
        "        avg_reward = evaluate_model(loaded_model, env)\n",
        "        print(f\"Average reward: {avg_reward}\")\n",
        "\n",
        "        # Visualize evaluation metrics\n",
        "        visualize_evaluation_metrics([avg_reward])"
      ],
      "metadata": {
        "id": "hudoZLyI_5FX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing & Validation\n",
        "\n",
        "import unittest\n",
        "from stable_baselines3 import PPO\n",
        "import numpy as np\n",
        "\n",
        "class TestVizdoomEnv(unittest.TestCase):\n",
        "    def setUp(self):\n",
        "        self.env = VizdoomEnv(LOCAL_SCENARIO_PATH)\n",
        "\n",
        "    def test_initialization(self):\n",
        "        self.assertIsInstance(self.env, gym.Env)\n",
        "        self.assertIsNotNone(self.env.game)\n",
        "        self.assertEqual(self.env.frame_skip, 4)\n",
        "\n",
        "    def test_step(self):\n",
        "        state, reward, done, _, _ = self.env.step(0)\n",
        "        self.assertEqual(state.shape, self.env.observation_space.shape)\n",
        "        self.assertIsInstance(reward, float)\n",
        "        self.assertIsInstance(done, bool)\n",
        "\n",
        "    def test_reset(self):\n",
        "        state, _ = self.env.reset()\n",
        "        self.assertEqual(state.shape, self.env.observation_space.shape)\n",
        "\n",
        "    def test_close(self):\n",
        "        self.env.close()\n",
        "        self.assertFalse(self.env.game.is_running())\n",
        "\n",
        "class TestPPOAgent(unittest.TestCase):\n",
        "    def setUp(self):\n",
        "        self.env = VizdoomEnv(LOCAL_SCENARIO_PATH)\n",
        "        self.env = Monitor(self.env, LOCAL_LOG_PATH)\n",
        "        self.model = PPO(\"CnnPolicy\", self.env, verbose=1, tensorboard_log=LOCAL_TENSORBOARD_PATH)\n",
        "\n",
        "    def test_initialization(self):\n",
        "        self.assertIsInstance(self.model, PPO)\n",
        "\n",
        "    def test_training(self):\n",
        "        try:\n",
        "            self.model.learn(total_timesteps=100)\n",
        "            self.assertTrue(True)\n",
        "        except Exception as e:\n",
        "            self.fail(f\"Training failed with exception: {e}\")\n",
        "\n",
        "    def test_save_load(self):\n",
        "        model_path = os.path.join(LOCAL_MODEL_PATH, \"test_model\")\n",
        "        self.model.save(model_path)\n",
        "        loaded_model = PPO.load(model_path)\n",
        "        self.assertIsInstance(loaded_model, PPO)\n",
        "\n",
        "class TestModelManagement(unittest.TestCase):\n",
        "    def setUp(self):\n",
        "        self.env = VizdoomEnv(LOCAL_SCENARIO_PATH)\n",
        "        self.env = Monitor(self.env, LOCAL_LOG_PATH)\n",
        "        self.model = PPO(\"CnnPolicy\", self.env, verbose=1, tensorboard_log=LOCAL_TENSORBOARD_PATH)\n",
        "\n",
        "    def test_save_model_with_version(self):\n",
        "        model_save_path = os.path.join(LOCAL_MODEL_PATH, \"ppo_vizdoom\")\n",
        "        model_version = 1\n",
        "        save_model_with_version(self.model, model_save_path, model_version)\n",
        "        self.assertTrue(os.path.exists(f\"{model_save_path}_v{model_version}\"))\n",
        "\n",
        "    def test_load_model_with_validation(self):\n",
        "        model_save_path = os.path.join(LOCAL_MODEL_PATH, \"ppo_vizdoom_v1\")\n",
        "        self.model.save(model_save_path)\n",
        "        loaded_model = load_model_with_validation(model_save_path)\n",
        "        self.assertIsInstance(loaded_model, PPO)\n",
        "\n",
        "    def test_evaluate_model(self):\n",
        "        avg_reward = evaluate_model(self.model, self.env, num_episodes=5)\n",
        "        self.assertIsInstance(avg_reward, float)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    unittest.main(argv=[''], exit=False)"
      ],
      "metadata": {
        "id": "gU3-8Xqv_-sL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}